{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "$.getScript('https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages.\n",
    "%matplotlib inline \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline \n",
    "np.set_printoptions(suppress=True)\n",
    "from matplotlib.pyplot import figure\n",
    "#From Scikit Learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection  import train_test_split, cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# machine learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\JM025575\\\\Predictive Models Class\\\\data'"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JM025575\\Predictive Models Class\\data\n"
     ]
    }
   ],
   "source": [
    "cd /Users/JM025575/Predictive Models Class/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "combine = [train_df, test_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Target Variable and Move to Target to Column 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  PassengerId  Pclass  \\\n",
       "0         0            1       3   \n",
       "1         1            2       1   \n",
       "2         1            3       3   \n",
       "3         1            4       1   \n",
       "4         0            5       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate target variable name and move the target variable of 'Survived' to my first column for easier use.\n",
    "targetName = 'Survived'\n",
    "targetSeries = train_df[targetName]\n",
    "#remove target from current location and insert in collum 0\n",
    "del train_df[targetName]\n",
    "train_df.insert(0, targetName, targetSeries)\n",
    "#reprint dataframe and see target is in position 0\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>223.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>446.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>668.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived  PassengerId      Pclass         Age       SibSp  \\\n",
       "count  891.000000   891.000000  891.000000  714.000000  891.000000   \n",
       "mean     0.383838   446.000000    2.308642   29.699118    0.523008   \n",
       "std      0.486592   257.353842    0.836071   14.526497    1.102743   \n",
       "min      0.000000     1.000000    1.000000    0.420000    0.000000   \n",
       "25%      0.000000   223.500000    2.000000   20.125000    0.000000   \n",
       "50%      0.000000   446.000000    3.000000   28.000000    0.000000   \n",
       "75%      1.000000   668.500000    3.000000   38.000000    1.000000   \n",
       "max      1.000000   891.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.472826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.242363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived\n",
       "0       1  0.629630\n",
       "1       2  0.472826\n",
       "2       3  0.242363"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Survival average by passenger class\n",
    "train_df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex  Survived\n",
       "0  female  0.742038\n",
       "1    male  0.188908"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Survival by sex\n",
    "train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parch</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.550847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.343658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Parch  Survived\n",
       "3      3  0.600000\n",
       "1      1  0.550847\n",
       "2      2  0.500000\n",
       "0      0  0.343658\n",
       "5      5  0.200000\n",
       "4      4  0.000000\n",
       "6      6  0.000000"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Survival by number of parents/children aboard ship\n",
    "train_df[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived         int64\n",
       "PassengerId      int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  PassengerId  Pclass  \\\n",
       "0         0            1       3   \n",
       "1         1            2       1   \n",
       "2         1            3       3   \n",
       "3         1            4       1   \n",
       "4         0            5       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived\n",
       "0    549\n",
       "1    342\n",
       "dtype: int64"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('Survived').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    216\n",
       "2    184\n",
       "3    491\n",
       "dtype: int64"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('Pclass').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    314\n",
       "male      577\n",
       "dtype: int64"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('Sex').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "C    168\n",
       "Q     77\n",
       "S    644\n",
       "dtype: int64"
      ]
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('Embarked').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting out the title to use this instead of Name as a predictive feature\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Capt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Col</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Countess</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Don</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jonkheer</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mme</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rev</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sir</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex       female  male\n",
       "Title                 \n",
       "Capt           0     1\n",
       "Col            0     2\n",
       "Countess       1     0\n",
       "Don            0     1\n",
       "Dr             1     6\n",
       "Jonkheer       0     1\n",
       "Lady           1     0\n",
       "Major          0     2\n",
       "Master         0    40\n",
       "Miss         182     0\n",
       "Mlle           2     0\n",
       "Mme            1     0\n",
       "Mr             0   517\n",
       "Mrs          125     0\n",
       "Ms             1     0\n",
       "Rev            0     6\n",
       "Sir            0     1"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train_df['Title'], train_df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to reduce the number of categories for Title\n",
    "for dataset in combine:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n",
    " \t'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Sex</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Sex     female  male\n",
       "Title               \n",
       "Master       0    40\n",
       "Miss       185     0\n",
       "Mr           0   517\n",
       "Mrs        126     0\n",
       "Other        3    20"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train_df['Title'], train_df['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving off PassengerID for later use\n",
    "passengerid = test_df.PassengerId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping two columns that I do not believe will enhance the predictive power of my models\n",
    "train_df = train_df.drop(['Ticket', 'Cabin', 'PassengerId', 'Name'], axis=1)\n",
    "test_df = test_df.drop(['Ticket', 'Cabin', 'Name', 'PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>Mrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Mr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked Title\n",
       "0         0       3    male  22.0      1      0   7.2500        S    Mr\n",
       "1         1       1  female  38.0      1      0  71.2833        C   Mrs\n",
       "2         1       3  female  26.0      0      0   7.9250        S  Miss\n",
       "3         1       1  female  35.0      1      0  53.1000        S   Mrs\n",
       "4         0       3    male  35.0      0      0   8.0500        S    Mr"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-Score Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will go through and run a z-score normalization for all numeric values to ensure no one feature has an undue influence on our models below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform numeric features to Z-Scores\n",
    "train_df.Age=pd.DataFrame((train_df.Age - train_df.Age.mean())/train_df.Age.std())\n",
    "train_df.Fare=pd.DataFrame((train_df.Fare - train_df.Fare.mean())/train_df.Fare.std())\n",
    "test_df.Age=pd.DataFrame((test_df.Age - test_df.Age.mean())/test_df.Age.std())\n",
    "test_df.Fare=pd.DataFrame((test_df.Fare - test_df.Fare.mean())/test_df.Fare.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Variables to Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le_dep = preprocessing.LabelEncoder()\n",
    "#to convert into numbers\n",
    "train_df.Survived = le_dep.fit_transform(train_df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform data transformation. Creates dummies of any categorical feature and turns them in to their own column with values of \n",
    "# 0 or 1.\n",
    "for col in train_df.columns[1:]:\n",
    "\tattName = col\n",
    "\tdType = train_df[col].dtype\n",
    "\tmissing = pd.isnull(train_df[col]).any()\n",
    "\tuniqueCount = len(train_df[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\ttrain_df = pd.concat([train_df, pd.get_dummies(train_df[col], prefix=col)], axis=1)\n",
    "\t\tdel train_df[attName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform data transformation. Creates dummies of any categorical feature and turns them in to their own column with values of \n",
    "# 0 or 1.\n",
    "for col in test_df.columns[0:]:\n",
    "\tattName = col\n",
    "\tdType = test_df[col].dtype\n",
    "\tmissing = pd.isnull(test_df[col]).any()\n",
    "\tuniqueCount = len(test_df[attName].value_counts(normalize=False))\n",
    "\t# discretize (create dummies)\n",
    "\tif dType == object:\n",
    "\t\ttest_df = pd.concat([test_df, pd.get_dummies(test_df[col], prefix=col)], axis=1)\n",
    "\t\tdel test_df[attName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Validating that there are no null values\n",
    "feat_miss = train_df.columns[train_df.isnull().any()]\n",
    "print(feat_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Age values, filling in with median values\n",
    "train_df = train_df.fillna(train_df.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Age', 'Fare'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Validating that there are no null values\n",
    "feat_miss = test_df.columns[test_df.isnull().any()]\n",
    "print(feat_miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Age and Fare values, filling in with median values\n",
    "test_df = test_df.fillna(test_df.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset into Train/Test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create a training and test data set from train_df that will be used in the models below.  I will use a 33/67 split for the test vs train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_df.drop(['Survived'], axis = 1)\n",
    "target = train_df[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, target_train, target_test = train_test_split(features,target,test_size = .33, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my first models I will run Decision Trees to get an initial hold on how stable the data is and to check quickly for an overfitting of the models to the data.  Based on the results of these models I will determine what additional predictive models I will run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree - Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree \n",
    "clf_dt = tree.DecisionTreeClassifier() #taking out of box options. \n",
    "#Call up the model to see the parameters you can tune (and their default setting)\n",
    "print(clf_dt)\n",
    "#Fit clf to the training data\n",
    "clf_dt = clf_dt.fit(features_train, target_train)\n",
    "#Predict clf DT model again test data\n",
    "target_predicted_dt = clf_dt.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7694915254237288\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.83      0.82       184\n",
      "          1       0.70      0.68      0.69       111\n",
      "\n",
      "avg / total       0.77      0.77      0.77       295\n",
      "\n",
      "[[152  32]\n",
      " [ 36  75]]\n"
     ]
    }
   ],
   "source": [
    "DT_1 = accuracy_score(target_test, target_predicted_dt)\n",
    "print(DT_1)\n",
    "print(classification_report(target_test, target_predicted_dt))\n",
    "print(confusion_matrix(target_test, target_predicted_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.78688525 0.81666667 0.83333333 0.71666667 0.8        0.74576271\n",
      " 0.62711864 0.79661017 0.79661017 0.79661017]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7716263776975085"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(clf_dt, features_train, target_train, cv=10)  #it is sampling from each of the data sets, usually sampling 50% out of each\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decison Tree - Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=5,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='random')\n"
     ]
    }
   ],
   "source": [
    "clf_dt = tree.DecisionTreeClassifier(splitter = 'random' , min_samples_split = 5, max_depth = 7) \n",
    "#Call up the model to see the parameters you can tune (and their default setting)\n",
    "print(clf_dt)\n",
    "#Fit clf to the training data\n",
    "clf_dt = clf_dt.fit(features_train, target_train)\n",
    "#Predict clf DT model again test data\n",
    "target_predicted_dt = clf_dt.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372881355932204\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.90      0.87       184\n",
      "          1       0.82      0.73      0.77       111\n",
      "\n",
      "avg / total       0.84      0.84      0.84       295\n",
      "\n",
      "[[166  18]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "DT_2 = accuracy_score(target_test, target_predicted_dt)\n",
    "print(DT_2)\n",
    "print(classification_report(target_test, target_predicted_dt))\n",
    "print(confusion_matrix(target_test, target_predicted_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validate Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.78688525 0.81666667 0.88333333 0.75       0.81666667 0.83050847\n",
      " 0.69491525 0.84745763 0.86440678 0.83050847]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8121348522737797"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify DT with Cross Validation\n",
    "scores = cross_val_score(clf_dt, features_train, target_train, cv=10)  #it is sampling from each of the data sets, usually sampling 50% out of each\n",
    "print(\"Cross Validation Score for each K\",scores)\n",
    "scores.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran two Decision Tree models to start off with.  The first took the out of the box options and got an accuracy score of 0.769.  I cross validated this model 10 times and got a wide range of values from 0.62 to 0.83.  This shows me the out of the box option may have some overfitting.  I then ran a second model adjusting the splitter to random, the min_samples_split to 5 and the max_depth to 7.  This increased my accuracy score to 0.837 as well as gains in Precision and Recall to 0.82 and 0.73 respectively.  I again cross validated to see if the overfitting had been reduced.  I got a smaller range of values from 0.69 to 0.88 but still think the Decision Tree models are not my best option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will run various Random Forest models to try and improve on my accuracy scores as well as find a model that is not overfit to the train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8169491525423729\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.84      0.88      0.86       184\n",
      "        Yes       0.78      0.72      0.75       111\n",
      "\n",
      "avg / total       0.82      0.82      0.82       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "# train random forest model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "RF_1 = accuracy_score(target_test, target_predicted_rf)\n",
    "print(RF_1)\n",
    "target_names = [\"No\", \"Yes\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.78688525 0.8        0.83333333 0.8        0.83333333 0.76271186\n",
      " 0.6779661  0.84745763 0.81355932 0.83050847]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7985755302398815"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Random Forest with Cross Validation\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_rf)\n",
    "scores_rf.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8067796610169492\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.84      0.85      0.85       184\n",
      "        Yes       0.75      0.74      0.74       111\n",
      "\n",
      "avg / total       0.81      0.81      0.81       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators= 900, n_jobs=4,oob_score=True)\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "RF_2 = accuracy_score(target_test, target_predicted_rf)\n",
    "print(RF_2)\n",
    "target_names = [\"No\", \"Yes\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.7704918  0.76666667 0.86666667 0.75       0.85       0.83050847\n",
      " 0.69491525 0.86440678 0.83050847 0.84745763]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8071621746781513"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Random Forest with Cross Validation\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_rf)\n",
    "scores_rf.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8271186440677966\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      0.86      0.86       184\n",
      "        Yes       0.77      0.77      0.77       111\n",
      "\n",
      "avg / total       0.83      0.83      0.83       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators= 100, criterion = 'entropy', min_samples_split = 5 )\n",
    "rf.fit(features_train, target_train)\n",
    "# test random forest model\n",
    "target_predicted_rf = rf.predict(features_test)\n",
    "RF_3 = accuracy_score(target_test, target_predicted_rf)\n",
    "print(RF_3)\n",
    "target_names = [\"No\", \"Yes\"]\n",
    "print(classification_report(target_test, target_predicted_rf, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.83606557 0.81666667 0.85       0.76666667 0.85       0.81355932\n",
      " 0.71186441 0.84745763 0.86440678 0.83050847]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8187195517273317"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Random Forest with Cross Validation\n",
    "scores_rf = cross_val_score(rf, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_rf)\n",
    "scores_rf.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran three Random Forest models.  The first model took the out of the box options and got an accuracy score of 0.817.  This model was cross validated 10 times and again we got too wide of a range of accuracy score from 0.67 to 0.84.  For my second Random Forest model, I adjust the n_estimators to 900, n_jobs to 4, and oob_score to True and got a lower accuracy score of 0.807.  Cross validating 10 times again showed a wider range of values ranging nearly 15%. For my final model, I set n_estimators to 100, criterion to 'entropy', and min_samples_split to 5 and increased my accuracy score to 0.827.  Cross validation showed a tighter range of accuracy score values showing that thus far my third Random Forest model is my best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am continuing to pursue a higher accuracy score while still not creating an overfit model.  I will run various Gradient Boosting models in my attempt to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8338983050847457\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.85      0.89      0.87       184\n",
      "        Yes       0.80      0.74      0.77       111\n",
      "\n",
      "avg / total       0.83      0.83      0.83       295\n",
      "\n",
      "[[164  20]\n",
      " [ 29  82]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf_GBC = GradientBoostingClassifier()\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "expected = target_test\n",
    "GB_1 = accuracy_score(expected,predicted_GBC)\n",
    "print(GB_1)\n",
    "print(classification_report(expected, predicted_GBC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_GBC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.86885246 0.81666667 0.9        0.78333333 0.85       0.81355932\n",
      " 0.74576271 0.93220339 0.89830508 0.89830508]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8506988052236732"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Gradient Boosting with Cross Validation\n",
    "scores_gb = cross_val_score(clf_GBC, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_gb)\n",
    "scores_gb.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305084745762712\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.85      0.89      0.87       184\n",
      "        Yes       0.80      0.74      0.77       111\n",
      "\n",
      "avg / total       0.83      0.83      0.83       295\n",
      "\n",
      "[[163  21]\n",
      " [ 29  82]]\n"
     ]
    }
   ],
   "source": [
    "clf_GBC = GradientBoostingClassifier(n_estimators=200)\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "expected = target_test\n",
    "GB_2 = accuracy_score(expected,predicted_GBC)\n",
    "print(GB_2)\n",
    "print(classification_report(expected, predicted_GBC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_GBC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.83606557 0.83333333 0.91666667 0.76666667 0.85       0.79661017\n",
      " 0.77966102 0.89830508 0.84745763 0.86440678]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8389172918403262"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Gradient Boosting with Cross Validation\n",
    "scores_gb = cross_val_score(clf_GBC, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_gb)\n",
    "scores_gb.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8372881355932204\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.85      0.89      0.87       184\n",
      "        Yes       0.81      0.75      0.78       111\n",
      "\n",
      "avg / total       0.84      0.84      0.84       295\n",
      "\n",
      "[[164  20]\n",
      " [ 28  83]]\n"
     ]
    }
   ],
   "source": [
    "clf_GBC = GradientBoostingClassifier(n_estimators=100, min_samples_split = 5)\n",
    "clf_GBC.fit(features_train, target_train)\n",
    "predicted_GBC=clf_GBC.predict(features_test)\n",
    "expected = target_test\n",
    "GB_3 = accuracy_score(expected,predicted_GBC)\n",
    "print(GB_3)\n",
    "print(classification_report(expected, predicted_GBC,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_GBC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.83606557 0.81666667 0.9        0.76666667 0.86666667 0.81355932\n",
      " 0.76271186 0.91525424 0.89830508 0.88135593]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8457252014448459"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Gradient Boosting with Cross Validation\n",
    "scores_gb = cross_val_score(clf_GBC, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_gb)\n",
    "scores_gb.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran three Gradient Boosting models.  The first model took the out of the box options and got an accuracy score of 0.834.  I cross validated 10 times and saw better results than in previous models with a roughly 15% range in accuracy values.  This is still too high but we are improving.  My second model I adjusted n_estimators to 200 and got an accuracy score of 0.830 again.  Cross validation again showed similar results.  I ran one final Gradient Boosting model where I put n_estimators back to 100 and set my min_samples_split to 5 and got an accuracy score of 0.837.  This model also produced my best Precision and Recall at 0.81 and 0.75 respectively.  Cross validating 10 times still shows a wide range of roughly 15%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will run various Bagging Classifier models with the intention of improving accuracy while creating a model that is not overfit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
      "         verbose=0, warm_start=False)\n",
      "0.8169491525423729\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.83      0.89      0.86       184\n",
      "        Yes       0.79      0.69      0.74       111\n",
      "\n",
      "avg / total       0.82      0.82      0.81       295\n",
      "\n",
      "[[164  20]\n",
      " [ 34  77]]\n"
     ]
    }
   ],
   "source": [
    "#Bagging Classifer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf_bag = BaggingClassifier()\n",
    "print(clf_bag)\n",
    "clf_bag.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag.predict(features_test)\n",
    "expected = target_test\n",
    "BC_1 = accuracy_score(expected,predicted_bag)\n",
    "print(BC_1)\n",
    "print(classification_report(expected, predicted_bag,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.80327869 0.8        0.9        0.78333333 0.83333333 0.81355932\n",
      " 0.6779661  0.86440678 0.79661017 0.76271186]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8035199592479392"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Bagging Classifier with Cross Validation\n",
    "scores_bc = cross_val_score(clf_bag, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_bc)\n",
    "scores_bc.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=True, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=333, n_jobs=1, oob_score=False, random_state=21,\n",
      "         verbose=0, warm_start=False)\n",
      "0.8440677966101695\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.86      0.89      0.88       184\n",
      "        Yes       0.81      0.77      0.79       111\n",
      "\n",
      "avg / total       0.84      0.84      0.84       295\n",
      "\n",
      "[[164  20]\n",
      " [ 26  85]]\n"
     ]
    }
   ],
   "source": [
    "clf_bag = BaggingClassifier(n_estimators=333, random_state=21,bootstrap_features = True)\n",
    "print(clf_bag)\n",
    "clf_bag.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag.predict(features_test)\n",
    "expected = target_test\n",
    "BC_2 = accuracy_score(expected,predicted_bag)\n",
    "print(BC_2)\n",
    "print(classification_report(expected, predicted_bag,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.80327869 0.81666667 0.91666667 0.78333333 0.86666667 0.83050847\n",
      " 0.69491525 0.88135593 0.83050847 0.83050847]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8254408632027415"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Bagging Classifier with Cross Validation\n",
    "scores_bc = cross_val_score(clf_bag, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_bc)\n",
    "scores_bc.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
      "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
      "         n_estimators=201, n_jobs=4, oob_score=False, random_state=0,\n",
      "         verbose=0, warm_start=False)\n",
      "0.8169491525423729\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.85      0.85      0.85       184\n",
      "        Yes       0.76      0.76      0.76       111\n",
      "\n",
      "avg / total       0.82      0.82      0.82       295\n",
      "\n",
      "[[157  27]\n",
      " [ 27  84]]\n"
     ]
    }
   ],
   "source": [
    "clf_bag = BaggingClassifier(n_estimators=201, random_state = 0, n_jobs = 4)\n",
    "print(clf_bag)\n",
    "clf_bag.fit(features_train, target_train)\n",
    "predicted_bag=clf_bag.predict(features_test)\n",
    "expected = target_test\n",
    "BC_3 = accuracy_score(expected,predicted_bag)\n",
    "print(BC_3)\n",
    "print(classification_report(expected, predicted_bag,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_bag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.78688525 0.8        0.83333333 0.78333333 0.85       0.77966102\n",
      " 0.66101695 0.84745763 0.84745763 0.81355932]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8002704454941186"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify Random Forest with Cross Validation\n",
    "scores_bc = cross_val_score(clf_bag, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_bc)\n",
    "scores_bc.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran 3 differnt Bagging Classifier models.  The first model took the out of the box features and got an accuracy score of 0.817.  Cross validation showed a large amount of overfitting as the accuracy scores ranged nearly 23%.  My second model I changed the n_estimators to 333, random_state to 21, and bootstrap_features to True and increased my accuracy score to 0.844, my highest thus far.  Cross validation again though showed too wide of a range of results.  My final Bagging Classifier model I set the n_estimators to 201, random_state to 0 and n_jobs to 4. This resulted in an accuracy score of 0.817.  Cross validation again confirmed that the Bagging Classifier models are too overfit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will run multiple KNN models as I continue to pursue an accurate model that is not overfit to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85       184\n",
      "          1       0.75      0.77      0.76       111\n",
      "\n",
      "avg / total       0.82      0.82      0.82       295\n",
      "\n",
      "[[156  28]\n",
      " [ 26  85]]\n",
      "0.8169491525423729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "neigh = KNeighborsClassifier()\n",
    "neigh.fit(features_train, target_train) \n",
    "predicted_KNN1 = neigh.predict(features_test)\n",
    "print(neigh)\n",
    "# make predictions\n",
    "#print(target_test)\n",
    "# summarize the fit of the model\n",
    "print(classification_report(target_test, predicted_KNN1))\n",
    "print(confusion_matrix(target_test, predicted_KNN1))\n",
    "KNN_1 = accuracy_score(target_test,predicted_KNN1)\n",
    "print(KNN_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.81967213 0.78333333 0.9        0.76666667 0.83333333 0.84745763\n",
      " 0.74576271 0.86440678 0.81355932 0.84745763]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8221649532277484"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify KNN with Cross Validation\n",
    "scores_KNN = cross_val_score(neigh, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_KNN)\n",
    "scores_KNN.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=7, p=1,\n",
      "           weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.85      0.85       184\n",
      "          1       0.75      0.75      0.75       111\n",
      "\n",
      "avg / total       0.81      0.81      0.81       295\n",
      "\n",
      "[[156  28]\n",
      " [ 28  83]]\n",
      "0.8101694915254237\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=7, p = 1)\n",
    "neigh.fit(features_train, target_train) \n",
    "predicted_KNN1 = neigh.predict(features_test)\n",
    "print(neigh)\n",
    "# make predictions\n",
    "#print(target_test)\n",
    "# summarize the fit of the model\n",
    "print(classification_report(target_test, predicted_KNN1))\n",
    "print(confusion_matrix(target_test, predicted_KNN1))\n",
    "KNN_2 = accuracy_score(target_test,predicted_KNN1)\n",
    "print(KNN_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.86885246 0.81666667 0.86666667 0.75       0.8        0.77966102\n",
      " 0.76271186 0.88135593 0.88135593 0.88135593]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.828862647031583"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify KNN with Cross Validation\n",
    "scores_KNN = cross_val_score(neigh, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_KNN)\n",
    "scores_KNN.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=13, p=1,\n",
      "           weights='distance')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.86      0.85       184\n",
      "          1       0.75      0.72      0.74       111\n",
      "\n",
      "avg / total       0.81      0.81      0.81       295\n",
      "\n",
      "[[158  26]\n",
      " [ 31  80]]\n",
      "0.8067796610169492\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors = 13, p = 1, weights = 'distance')\n",
    "neigh.fit(features_train, target_train) \n",
    "predicted_KNN1 = neigh.predict(features_test)\n",
    "print(neigh)\n",
    "# make predictions\n",
    "#print(target_test)\n",
    "# summarize the fit of the model\n",
    "print(classification_report(target_test, predicted_KNN1))\n",
    "print(confusion_matrix(target_test, predicted_KNN1))\n",
    "KNN_3 = accuracy_score(target_test,predicted_KNN1)\n",
    "print(KNN_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.80327869 0.78333333 0.86666667 0.78333333 0.83333333 0.83050847\n",
      " 0.71186441 0.88135593 0.81355932 0.88135593]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8188589422987868"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify KNN with Cross Validation\n",
    "scores_KNN = cross_val_score(neigh, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_KNN)\n",
    "scores_KNN.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran three KNN models.  The first model used the out of the box parameters and got an accuracy score of 0.817. I cross validated to check for model overfitting, and similar to previous models see signs of this happening with accuracy scores ranging from 0.74 to 0.9.  My second KNN model I set n_neighbors to 7 and p = 1 and got an accuracy score of 0.810.  Cross validation did show less signs of overfitting with the range this time between 0.75 and 0.88.  My final KNN model had n_neighbors set to 13, p = 1, and weights = 'distance'.  This produced an accuracy score of 0.807.  I cross validated this model as well to similar results with too wide a range of values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM RBF Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will run various SVM RBF models to tru and obtain my highest accuracy score while not overfitting the model to my data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM RBF Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.85      0.87      0.86       184\n",
      "        Yes       0.77      0.74      0.76       111\n",
      "\n",
      "avg / total       0.82      0.82      0.82       295\n",
      "\n",
      "[[160  24]\n",
      " [ 29  82]]\n",
      "0.8203389830508474\n"
     ]
    }
   ],
   "source": [
    "#standard RBF SVM Model\n",
    "clf_rbf = SVC(kernel='rbf', C=1.0, gamma='auto')\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_SVM=clf_rbf.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "RBF_1 = accuracy_score(expected,predicted_SVM)\n",
    "print(RBF_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate SVM RBF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.81967213 0.78333333 0.91666667 0.76666667 0.83333333 0.84745763\n",
      " 0.77966102 0.88135593 0.88135593 0.88135593]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8390858571825508"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_SVMR = cross_val_score(clf_rbf, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_SVMR)\n",
    "scores_SVMR.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMV RBF Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         No       0.83      0.92      0.88       184\n",
      "        Yes       0.85      0.69      0.76       111\n",
      "\n",
      "avg / total       0.84      0.84      0.83       295\n",
      "\n",
      "[[170  14]\n",
      " [ 34  77]]\n",
      "0.8372881355932204\n"
     ]
    }
   ],
   "source": [
    "clf_rbf = SVC(kernel='rbf', C=21.0)\n",
    "clf_rbf.fit(features_train, target_train)\n",
    "predicted_SVM=clf_rbf.predict(features_test)\n",
    "expected = target_test\n",
    "# summarize the fit of the model\n",
    "print(classification_report(expected, predicted_SVM,target_names=['No', 'Yes']))\n",
    "print(confusion_matrix(expected, predicted_SVM))\n",
    "RBF_2 = accuracy_score(expected,predicted_SVM)\n",
    "print(RBF_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate SVM RBF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.81967213 0.8        0.93333333 0.78333333 0.85       0.77966102\n",
      " 0.72881356 0.88135593 0.86440678 0.81355932]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.82541354079837"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_SVMR = cross_val_score(clf_rbf, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_SVMR)\n",
    "scores_SVMR.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran two separate Support Vector Machine RBF models.  The first one took the out of the box parameters and got an accuracy score of 0.820.  Cross validating 10 times showed a fair amount of overfitting with my accuracy scores ranging from 0.78 to 0.91, although still better than most of my models.  My second SVM RBF model I adjusted C to 21 and kept all other parameters the same and got an accuraracy of 0.837 and an increased Precision to 0.85. Cross validation showed similar overfitting to the first model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of models I will run will be Artificial Neural Networks.  I will run 3 models in hopes of obtaining my best accuracy score and best fit model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8305084745762712\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Salaray <= 50k       0.85      0.89      0.87       184\n",
      " Salary >= 50k       0.80      0.73      0.76       111\n",
      "\n",
      "   avg / total       0.83      0.83      0.83       295\n",
      "\n",
      "[[164  20]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf_ann =MLPClassifier()\n",
    "clf_ann.fit(features_train, target_train)\n",
    "target_predicted_ann = clf_ann.predict(features_test)\n",
    "ANN_1 = accuracy_score(target_test, target_predicted_ann)\n",
    "print('Accuracy', ANN_1)\n",
    "target_names = [\"Salaray <= 50k\", \"Salary >= 50k\"]\n",
    "print(classification_report(target_test, target_predicted_ann, target_names=target_names))\n",
    "print(confusion_matrix(target_test, target_predicted_ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.80327869 0.76666667 0.91666667 0.8        0.85       0.83050847\n",
      " 0.72881356 0.89830508 0.86440678 0.88135593]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8340001852366399"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ANN = cross_val_score(clf_ann, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_ANN)\n",
    "scores_ANN.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8271186440677966\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Salaray <= 50k       0.83      0.91      0.87       184\n",
      " Salary >= 50k       0.82      0.69      0.75       111\n",
      "\n",
      "   avg / total       0.83      0.83      0.82       295\n",
      "\n",
      "[[167  17]\n",
      " [ 34  77]]\n"
     ]
    }
   ],
   "source": [
    "clf_ann =MLPClassifier(hidden_layer_sizes=(50), max_iter=500, alpha=1e-05,\n",
    "                     random_state=21,tol=0.000000001)\n",
    "clf_ann.fit(features_train, target_train)\n",
    "target_predicted_ann = clf_ann.predict(features_test)\n",
    "ANN_2 = accuracy_score(target_test, target_predicted_ann)\n",
    "print('Accuracy', ANN_2)\n",
    "target_names = [\"Salaray <= 50k\", \"Salary >= 50k\"]\n",
    "print(classification_report(target_test, target_predicted_ann, target_names=target_names))\n",
    "print(confusion_matrix(target_test, target_predicted_ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.75409836 0.75       0.9        0.78333333 0.81666667 0.81355932\n",
      " 0.72881356 0.89830508 0.86440678 0.83050847]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8139691580994721"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ANN = cross_val_score(clf_ann, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_ANN)\n",
    "scores_ANN.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.823728813559322\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Salaray <= 50k       0.84      0.89      0.86       184\n",
      " Salary >= 50k       0.79      0.72      0.75       111\n",
      "\n",
      "   avg / total       0.82      0.82      0.82       295\n",
      "\n",
      "[[163  21]\n",
      " [ 31  80]]\n"
     ]
    }
   ],
   "source": [
    "clf_ann =MLPClassifier(hidden_layer_sizes=(150,150), max_iter=500,\n",
    "                     random_state=21)\n",
    "clf_ann.fit(features_train, target_train)\n",
    "target_predicted_ann = clf_ann.predict(features_test)\n",
    "ANN_3 = accuracy_score(target_test, target_predicted_ann)\n",
    "print('Accuracy', ANN_3)\n",
    "target_names = [\"Salaray <= 50k\", \"Salary >= 50k\"]\n",
    "print(classification_report(target_test, target_predicted_ann, target_names=target_names))\n",
    "print(confusion_matrix(target_test, target_predicted_ann))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validate ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score for each K [0.7704918  0.76666667 0.86666667 0.78333333 0.83333333 0.74576271\n",
      " 0.71186441 0.86440678 0.84745763 0.84745763]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.803744095582106"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ANN = cross_val_score(clf_ann, features_train, target_train, cv=10)  \n",
    "print(\"Cross Validation Score for each K\",scores_ANN)\n",
    "scores_ANN.mean()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran 3 separate neural network models.  The first model took the out of the box parameters and got an accuracy score of 0.831.  I cross validated this model 10 times and got a range of accuracy score values of nearly 20%.  I adjusted my second model to have my hidden layer size at 50, max_iter = 500, alpha = 1e-05, random_state = 21, and tol = 0.000000001.  This gave me an accuracy of 0.827.  Cross validation still showed a range of accuracy values of about 18%.  My final ANN model I simplified a bit by having all default parameters except for hidden layer sizes set to 150,150, max_iter = 500, and random_state = 21.  This produced an accuracy of 0.824.  This showed the least amount of overfitting in my cross validation with ranges from 0.71 to 0.86."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I will summarize the accuracy score values of all models I ran prior to choosing one that will be used with the test_df data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bagging Classifier 2</td>\n",
       "      <td>0.844068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree 2</td>\n",
       "      <td>0.837288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting 3</td>\n",
       "      <td>0.837288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RBF 2</td>\n",
       "      <td>0.837288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting 1</td>\n",
       "      <td>0.833898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gradient Boosting 2</td>\n",
       "      <td>0.833898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ANN 1</td>\n",
       "      <td>0.830508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ANN 2</td>\n",
       "      <td>0.827119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest 3</td>\n",
       "      <td>0.827119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ANN 3</td>\n",
       "      <td>0.823729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RBF 1</td>\n",
       "      <td>0.820339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bagging Classifier 3</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN 1</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bagging Classifier 1</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest 1</td>\n",
       "      <td>0.816949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN 2</td>\n",
       "      <td>0.810169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN 3</td>\n",
       "      <td>0.806780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest 2</td>\n",
       "      <td>0.806780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree 1</td>\n",
       "      <td>0.769492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model     Score\n",
       "9   Bagging Classifier 2  0.844068\n",
       "1        Decision Tree 2  0.837288\n",
       "7    Gradient Boosting 3  0.837288\n",
       "15                 RBF 2  0.837288\n",
       "5    Gradient Boosting 1  0.833898\n",
       "6    Gradient Boosting 2  0.833898\n",
       "16                 ANN 1  0.830508\n",
       "17                 ANN 2  0.827119\n",
       "4        Random Forest 3  0.827119\n",
       "18                 ANN 3  0.823729\n",
       "14                 RBF 1  0.820339\n",
       "10  Bagging Classifier 3  0.816949\n",
       "11                 KNN 1  0.816949\n",
       "8   Bagging Classifier 1  0.816949\n",
       "2        Random Forest 1  0.816949\n",
       "12                 KNN 2  0.810169\n",
       "13                 KNN 3  0.806780\n",
       "3        Random Forest 2  0.806780\n",
       "0        Decision Tree 1  0.769492"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Decision Tree 1', 'Decision Tree 2',\n",
    "              'Random Forest 1', 'Random Forest 2', 'Random Forest 3',\n",
    "              'Gradient Boosting 1', 'Gradient Boosting 2', 'Gradient Boosting 3',\n",
    "              'Bagging Classifier 1', 'Bagging Classifier 2', 'Bagging Classifier 3', \n",
    "              'KNN 1', 'KNN 2', 'KNN 3', \n",
    "              'RBF 1', 'RBF 2', \n",
    "              'ANN 1','ANN 2','ANN 3'],\n",
    "    'Score': [DT_1, DT_2, RF_1, RF_2, RF_3, GB_1, GB_2, GB_3, BC_1, BC_2, BC_3, \n",
    "                       KNN_1, KNN_2, KNN_3, RBF_1, RBF_2, ANN_1, ANN_2, ANN_3]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table shows that the Bagging Classifier 2 model had my best accuracy score.  This model though showed a great amount of overfitting as did the Decision Tree 2 and the RBF 2.  Because of this, and because of the strong Precision (0.81) and Recall (0.75) as well as the relatively low level of overfitting compared to my other models, I am choosing to use the Gradient Boosting 3 model as my submission for the Kaggle competition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.298099</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.497213</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1.179547</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.512045</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.237285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.463974</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.482308</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.583349</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.417469</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass       Age  SibSp  Parch      Fare  Sex_female  Sex_male  Embarked_C  \\\n",
       "0       3  0.298099      0      0 -0.497213           0         1           0   \n",
       "1       3  1.179547      1      0 -0.512045           1         0           0   \n",
       "2       2  2.237285      0      0 -0.463974           0         1           0   \n",
       "3       3 -0.230769      0      0 -0.482308           0         1           0   \n",
       "4       3 -0.583349      1      1 -0.417469           1         0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Title_Master  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "0           1           0             0           0         1          0   \n",
       "1           0           1             0           0         0          1   \n",
       "2           1           0             0           0         1          0   \n",
       "3           0           1             0           0         1          0   \n",
       "4           0           1             0           0         0          1   \n",
       "\n",
       "   Title_Other  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = clf_GBC.predict(test_df)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": passengerid,\n",
    "        \"Survived\": test_prediction\n",
    "    })\n",
    "\n",
    "submission.PassengerId = submission.PassengerId.astype(int)\n",
    "submission.Survived = submission.Survived.astype(int)\n",
    "\n",
    "submission.to_csv(\"titanic1_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
